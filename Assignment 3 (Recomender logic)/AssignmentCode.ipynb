{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomanació basada en PageRank\n",
    "\n",
    "L'algorisme PageRank, famós per l'ús en el cercador de Google, te moltes altres aplicacions. Un exemple d'ells és la recomanació d'items a usuaris basat en les similituds entre usuaris.\n",
    "\n",
    "Recordeu el principi de funcionament bàsic de les recomanacions colaboratives basades en l'usuari, obtenim una puntuació per a un item i usuari, basat en les similituds d'aquest usuari amb la resta, i respectives puntuacions. Si ho formulem, podríem dir que tot es basa en:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\frac{\\sum_{v,v\\neq u} sim(u,v) \\cdot r_{v,i}}{\\sum_{v,v\\neq u} sim(u,v)}$$\n",
    "\n",
    "Amb notació \n",
    "\n",
    "* $r_{u,i}$ ens indica la puntuació ($r$ating) de l'usuari $u$ a l'item $i$. \n",
    "* El sumatori $\\sum_{v,v\\neq u}$ indica la suma per cada usuari $v$ que no sigui el propi $u$ del que estem intentant predir una puntuació\n",
    "* El barret a $\\hat{r}$ denota que es tracta d'una predicció, el valor que estem intentant inferir a partir de les dades.\n",
    "\n",
    "La funció $sim$ és la que ens indica quan semblants són dos usuaris entre sí. Tal i com heu vist a teoria, això es pot fer amb mètriques com la distància euclidea o la similitud de Pearson, d'entre moltes altres. En aquesta pràctica, però, veure'm com el vector obtingut a partir de calcular PageRank sobre una matriu concreta d'usuaris i items, també ens proporciona una mesura de similitud significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia\n",
    "\n",
    "Per aquells interesats, tota la informació relativa a PageRank està basada en la publicació\n",
    "\n",
    "`Bryan, K., & Leise, T. (2006). The $25,000,000,000 eigenvector: The linear algebra behind Google. Siam Review, 48(3), 569-581.`\n",
    "\n",
    "I els algorismes matemàtiques en el llibre:\n",
    "\n",
    "`Applied numerical linear algebra, James W. Demmel`, capítol 4.4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank\n",
    "\n",
    "Aquesta cel·la serveix com a una breu recapitulació de l'algorisme PageRank vist a teoria. Recordem que PageRank es basa en trobar l'importància de les pàgines en base a la reputació d'aquestes i del número de links entrants i sortints.\n",
    "\n",
    "Supossa que tenim la següent estructura de pàgines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/page1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "És a dir, si comptem el número de `in-link` (enllaços d'entrada) de cada pàgina $x$, obtindríem:\n",
    "$$x_1=3,x_2=2,x_3=1,x_4=3$$\n",
    "\n",
    "Però també podem expressar-ho en funció de la pàgina de qui rebem el link, de forma que tinguem la importància en compte:\n",
    "\n",
    "$$x_{entrada} = \\dfrac{x_{sortida}}{|x_{sortida}|}$$\n",
    "\n",
    "Per exemple, si ho apliquem a $x_1$, $x_1 = x_2 / 2 + x_3 / 2 + x_4 / 3$. De forma semblant, podem aplicar-ho a la resta:\n",
    "\n",
    "$$x_1 = x_2 / 2 + x_3 / 2 + x_4 / 3$$\n",
    "$$x_2 = x_1 / 2 + x_4 / 3$$\n",
    "$$x_3 = x_4 / 3$$\n",
    "$$x_4 = x_1 / 2 + x_2 / 2 + x_3 / 2$$\n",
    "\n",
    "Ara podríem resoldre aquest sistema per trobar quina és la importància de cada web, un vector $(s_1,s_2,s_3,s_4)$. Però, resoldre-ho no és trivial (no en casos on tenim millors de webs, és clar!). Per tal de poder avançar, el que se sol fer és resoldre-ho en forma matricial:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "& \\text{Out-links} &\\\\\n",
    "G = &\\begin{bmatrix}\n",
    "    0 & 1/2 & 1/2 & 1/3 \\\\\n",
    "    1/2 & 0 & 0 & 1/3 \\\\\n",
    "    0 & 0 & 0 & 1/3 \\\\\n",
    "    1/2 & 1/2 & 1/2 & 0\n",
    "\\end{bmatrix} & \\text{In-links}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "El sistema ara es converteix en una equació, arquetip fàcilment reconegut pels matemàtics:\n",
    "\n",
    "$$x = Gx$$\n",
    "\n",
    "Trobareu els detalls a la publicació si esteu interesats, realment el que estem intentant és trobar el vector propi que té per valor propi 1. És a dir, resoldre $\\lambda x = Gx$ tal que $\\lambda = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trobant el vector propi\n",
    "\n",
    "Un dels mètodes més eficients, tot i que no el que més, és el mètode de la potència. Aquest, permet trobar el vector propi que té el valor propi més alt (coses de les matemàtiques, es pot demostrar que $\\lambda=1$ serà el més alt). El mètode diu així:\n",
    "\n",
    "$\n",
    "i = 0\\\\\n",
    "\\text{do}\\\\\n",
    "\\hspace{2cm}y_{i+1} = Gx_i\\\\\n",
    "\\hspace{2cm}x_{i+1} = y_{i+1} / ||y_{i+1}||_2\\\\\n",
    "\\hspace{2cm}i = i + 1\\\\\n",
    "\\text{until }||x_{i+1} - x_{i}|| < 10^{-6}\n",
    "$\n",
    "\n",
    "On $x_0$ és un vector normalitzat amb suma 1, per exemple si tenim $n$ webs en total $x_0 = \\textbf{1} / n$, on $\\textbf{1}$ és un vector d'1s de tamany $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programa l'algorisme del mètode de la potència amb numpy, seguint el pseudocodi de dalt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def power_method(G):\n",
    "    \"\"\"\n",
    "    Donada una matriu d'adjecències, en calcula el PageRank.\n",
    "    Mitjançant el mètode de la potència troba el vector propi\n",
    "    de valor propi màxim (1)\n",
    "    \n",
    "    :param G: Matriu a calcular el PageRank\n",
    "    :return: Vector d'importàncies del PageRank (vector\n",
    "        propi amb valor propi més alt)\n",
    "    \"\"\"\n",
    "    dimensioG = G.shape[0]\n",
    "    x = np.ones(dimensioG)/dimensioG #Normalitzem\n",
    "    while True:\n",
    "        xSeguent = G.dot(x) #Dot: multiplicacio\n",
    "        xSeguent = xSeguent/np.linalg.norm(xSeguent) #Diviim per la normalitzacio del seguent\n",
    "        if np.linalg.norm(xSeguent-x) < pow(10,-6): #Es tan petit com voliem?\n",
    "            return xSeguent\n",
    "        x = xSeguent #Si no, torna a iterar\n",
    "        \n",
    "        \n",
    "def solve_eig(G):\n",
    "    \"\"\"\n",
    "    Calcula els vectors i valors propis de la matriu G\n",
    "    mitjançant funcions de numpy. Funció de referència\n",
    "    que us pot servir per comprovar que el vostre mètode\n",
    "    power_method retorna el que toca.\n",
    "    \n",
    "    :param G: Matriu a calcular el PageRank\n",
    "    :return: Vector d'importàncies del PageRank (vector\n",
    "        propi amb valor propi més alt)\n",
    "    \"\"\"\n",
    "    vals, vecs = np.linalg.eig(G)\n",
    "    idxs = np.argsort(np.real(vals))\n",
    "    return np.abs(vecs[:, idxs[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.5   0.5   0.33]\n",
      " [ 0.5   0.    0.    0.33]\n",
      " [ 0.    0.    0.    0.33]\n",
      " [ 0.5   0.5   0.5   0.  ]]\n",
      "Eigenvector [ 0.56  0.49  0.21  0.63]\n",
      "Eigenvector [ 0.56  0.49  0.21  0.63]\n",
      "Eigenvalues [ 1.0+0.j -0.0+0.j -0.5+0.j -0.5-0.j]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    G1 = np.asarray((\n",
    "        (0,     1/2.0, 1/2.0, 1/3.0), \n",
    "        (1/2.0, 0,     0,     1/3.0), \n",
    "        (0,     0,     0,     1/3.0), \n",
    "        (1/2.0, 1/2.0, 1/2.0, 0)\n",
    "    ))\n",
    "    x = power_method(G1)\n",
    "    y = solve_eig(G1)\n",
    "    \n",
    "    print(np.round(G1, 2))\n",
    "    print('Eigenvector', np.round(x, 2))\n",
    "    print('Eigenvector', np.round(y, 2))\n",
    "    print('Eigenvalues', np.round(np.linalg.eigvals(G1), 2))\n",
    "    \n",
    "#Podem veure que obtenim els mateixos resultats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casos extrems\n",
    "\n",
    "Evidentment, no tot és tant bonic com sembla... Crea la matriu de la següent configuració i prova que passa quan n'executes el mètode de la potència:\n",
    "\n",
    "<img src=\"img/page2.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.5  0.5  0.   0. ]\n",
      " [ 0.5  0.   0.5  0.   0. ]\n",
      " [ 0.5  0.5  0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   1. ]\n",
      " [ 0.   0.   0.   1.   0. ]]\n",
      "Eigenvector [ 0.45  0.45  0.45  0.45  0.45]\n",
      "Eigenvector [ 0.    0.    0.    0.71  0.71]\n",
      "Eigenvalues [-0.5  1.  -0.5  1.  -1. ]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    G2 = np.asarray((\n",
    "        (0,     1/2.0, 1/2.0, 0,   0), \n",
    "        (1/2.0, 0,     1/2.0, 0,   0), \n",
    "        (1/2.0, 1/2.0, 0,     0,   0), \n",
    "        (0,     0,     0,     0,   1.0),\n",
    "        (0,     0,     0,     1.0, 0)\n",
    "    ))\n",
    "    x = power_method(G2)\n",
    "    y = solve_eig(G2)\n",
    "    \n",
    "    print(np.round(G2, 2))\n",
    "    print('Eigenvector', np.round(x, 2))\n",
    "    print('Eigenvector', np.round(y, 2))\n",
    "    print('Eigenvalues', np.round(np.linalg.eigvals(G2), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encara en trobem un més de cas extrem:\n",
    "\n",
    "<img src=\"img/page3.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.   0.5  0. ]\n",
      " [ 0.   0.   0.5  0. ]\n",
      " [ 1.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0. ]]\n",
      "Eigenvector [ 0.5   0.5   0.71  0.  ]\n",
      "Eigenvalues [ 0.    0.71 -0.71  0.  ]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    G3 = np.asarray((\n",
    "        (0,   0, 1/2.0, 0), \n",
    "        (0,   0, 1/2.0, 0), \n",
    "        (1.0, 0, 0,     0), \n",
    "        (0,   0, 0,     0)\n",
    "    ))\n",
    "    #x = power_method(G3)\n",
    "    y = solve_eig(G3)\n",
    "    \n",
    "    print(np.round(G3, 2))\n",
    "    print('Eigenvector', np.round(y, 2))\n",
    "    print('Eigenvalues', np.round(np.linalg.eigvals(G3), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solucions\n",
    "\n",
    "Per evitar tenir cicles, graphs separats i dangling nodes, el que es fa és modificar la matriu G amb \"soroll\", per tal de que tot quedi connectat amb tot. Aquesta tècnica a vegades rep el nom de \"Random Surfer\".\n",
    "\n",
    "$$M = (1 - m)G + mS$$\n",
    "\n",
    "On $S$ és una matriu amb totes les entrades $1/n$ i $m$ un nombre petit, normalment $0.15$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fes una funció que donada la matriu $G$ i $m$ calculi la nova matriu $M$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_matrix(G, m=0.15):\n",
    "    #\"Arreglem G\"\n",
    "    dimensioG = G.shape[0]\n",
    "    S = np.ones((dimensioG,dimensioG))/dimensioG #Calcul de S\n",
    "    return((np.dot(G,(1-m))+(np.dot(S,m)))) #Apliquem la formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03  0.45  0.45  0.03  0.03]\n",
      " [ 0.45  0.03  0.45  0.03  0.03]\n",
      " [ 0.45  0.45  0.03  0.03  0.03]\n",
      " [ 0.03  0.03  0.03  0.03  0.88]\n",
      " [ 0.03  0.03  0.03  0.88  0.03]]\n",
      "Eigenvector [ 0.45  0.45  0.45  0.45  0.45]\n",
      "Eigenvector [ 0.    0.    0.    0.71  0.71]\n",
      "Eigenvector [ 0.45  0.45  0.45  0.45  0.45]\n",
      "Eigenvalues [-0.43  1.    0.85 -0.43 -0.85]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    M2 = fix_matrix(G2)\n",
    "    x = power_method(M2)\n",
    "    y = solve_eig(G2)\n",
    "    z = solve_eig(M2)\n",
    "    \n",
    "    print(np.round(M2, 2))\n",
    "    print('Eigenvector', np.round(x, 2))\n",
    "    print('Eigenvector', np.round(y, 2))\n",
    "    print('Eigenvector', np.round(z, 2))\n",
    "    print('Eigenvalues', np.round(np.linalg.eigvals(M2), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04  0.04  0.46  0.04]\n",
      " [ 0.04  0.04  0.46  0.04]\n",
      " [ 0.89  0.04  0.04  0.04]\n",
      " [ 0.04  0.04  0.04  0.04]]\n",
      "Eigenvector [ 0.51  0.51  0.69  0.09]\n",
      "Eigenvector [ 0.5   0.5   0.71  0.  ]\n",
      "Eigenvector [ 0.51  0.51  0.69  0.09]\n",
      "Eigenvalues [ 0.72 -0.6   0.03  0.  ]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    M3 = fix_matrix(G3)\n",
    "    x = power_method(M3)\n",
    "    y = solve_eig(G3)\n",
    "    z = solve_eig(M3)\n",
    "    \n",
    "    print(np.round(M3, 2))\n",
    "    print('Eigenvector', np.round(x, 2))\n",
    "    print('Eigenvector', np.round(y, 2))\n",
    "    print('Eigenvector', np.round(z, 2))\n",
    "    print('Eigenvalues', np.round(np.linalg.eigvals(M3), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomanant\n",
    "\n",
    "El primer que haurem de fer és construir una matriu que ens serveixi, d'alguna forma, com a indicatiu de preferències de cada persona. Per tal efecte, construirem una matriu $m\\times n$, de $m$ usuaris per $n$ items, on cada entrada $i,j$ serà el nombre de vegades que la persona $i$ a comprat l'item $j$.\n",
    "\n",
    "<img src=\"img/Mat.png\">\n",
    "\n",
    "Per saber de quin usuari és cada `order_id`, haureu de creaur el dataset `order_products` amb el `orders`. Una sola persona/usuari tindrà més d'una ordre, mireu quants cops ha comprat els mateixos productes.\n",
    "\n",
    "A més, les dades es composen de molts `product_id` diferents, hi ha massa diversitat entre usuaris. Per tant, per poder recomanar el que farem serà agregar les dades, enlloc de treballar per `product_id` ho farem per `aisle_id`, és a dir \"la secció\" del súper on es troba.\n",
    "\n",
    "Al llarg de la pràctica es parlarà de producte i/o item, doncs és la terminologia estàndard de recomanadors, però sempre serà en referència a `aisle_id` per aquesta pràctica!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from os.path import join, dirname\n",
    "\n",
    "def locate(*path):\n",
    "    base = globals().get('__file__', '.')\n",
    "    return join(dirname(base), *path)\n",
    "\n",
    "def unzip(file):\n",
    "    zip_ref = zipfile.ZipFile(locate(file), 'r')\n",
    "    zip_ref.extractall(locate('data'))\n",
    "    zip_ref.close()\n",
    "\n",
    "unzip('order_products__train.csv.zip')\n",
    "unzip('orders.csv.zip')\n",
    "unzip('products.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_order_prods = pd.read_csv(locate('data', 'order_products__train.csv'))\n",
    "    df_orders = pd.read_csv(locate('data', 'orders.csv'))[['order_id', 'user_id']]\n",
    "    df_prods = pd.read_csv(locate('data', 'products.csv'))[['product_id', 'aisle_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df_order_prods)\n",
    "print(df_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  product_id  aisle_id\n",
      "0         112108       49302       120\n",
      "1          47901       49302       120\n",
      "2           2993       49302       120\n",
      "3          41425       49302       120\n",
      "4         187205       49302       120\n",
      "5         199120       49302       120\n",
      "6         145852       49302       120\n",
      "7          63189       49302       120\n",
      "8         112108       11109       108\n",
      "9          67333       11109       108\n",
      "10        158104       11109       108\n",
      "11        130713       11109       108\n",
      "12        118692       11109       108\n",
      "13         79511       11109       108\n",
      "14        143549       11109       108\n",
      "15         62061       11109       108\n",
      "16        131593       11109       108\n",
      "17         88538       11109       108\n",
      "18         27031       11109       108\n",
      "19        116218       11109       108\n",
      "20        200380       11109       108\n",
      "21         29758       11109       108\n",
      "22        112698       11109       108\n",
      "23         36560       11109       108\n",
      "24        199792       11109       108\n",
      "25        167055       11109       108\n",
      "26        121484       11109       108\n",
      "27        126266       11109       108\n",
      "28        135670       11109       108\n",
      "29        146522       11109       108\n",
      "...          ...         ...       ...\n",
      "1384587   199127       38975        36\n",
      "1384588    74676       31937        94\n",
      "1384589    32726       36532        81\n",
      "1384590    97146       45798        75\n",
      "1384591   194823         114        69\n",
      "1384592    61636       29899        63\n",
      "1384593   170845       49635        83\n",
      "1384594   189216       30800       108\n",
      "1384595   189216       40390        22\n",
      "1384596   192214       31527        45\n",
      "1384597   192214       18969        46\n",
      "1384598    54829       49046        47\n",
      "1384599    63499        6791       120\n",
      "1384600    46578       36888         9\n",
      "1384601   195393       31554        45\n",
      "1384602   159742        9073        81\n",
      "1384603     1528       14829       105\n",
      "1384604   167988       25791       111\n",
      "1384605    59184       39701       126\n",
      "1384606    47713       13738        45\n",
      "1384607    47713       25603        21\n",
      "1384608   154031        8360         5\n",
      "1384609    35607       40636        94\n",
      "1384610   177077       27645        97\n",
      "1384611   177077       25275         5\n",
      "1384612   177077        1528        97\n",
      "1384613     9808       47935        73\n",
      "1384614     9808        9491        25\n",
      "1384615    72444       16380        97\n",
      "1384616    20949       38900         5\n",
      "\n",
      "[1384617 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ### Creua df_order_prods i df_orders\n",
    "    df_merged = df_order_prods.set_index('order_id').join(df_orders.set_index('order_id'))\n",
    "    #Ara user id ajunta-ho amb product_id i aisle_id\n",
    "    df_merged = pd.merge(df_merged, df_prods)[['user_id','product_id','aisle_id']]\n",
    "    print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fes la funció que retorna els productes comprats en cada `aisle_id` per cada `user_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_counts_table(df):\n",
    "    \"\"\"\n",
    "    Retorna un dataframe on les columnes són els `aisle_id`, les files `user_id` i els valors\n",
    "    el nombre de vegades que un usuari ha comprat un producte d'un `aisle_id`\n",
    "    \n",
    "    :param df: DataFrame original després de creuar-lo\n",
    "    :return: DataFrame descrit adalt\n",
    "    \"\"\"\n",
    "    df = df.groupby(['user_id','aisle_id']).size() #Agrupa o \"ordena\" el DataFrame segons cada usuari i el seu aisle_id\n",
    "    return df.unstack().fillna(0) #Unstack: per pivotar el DataFrame en columnes. Fillna: posar un zero a on hi hagi un NaN\n",
    "\n",
    "def get_count(df, user_id, aisle_id):\n",
    "    \"\"\"\n",
    "    Retorna el nombre de vegades que un usuari ha comprat en un `aisle_id`\n",
    "    \n",
    "    :param df: DataFrame retornat per `build_counts_table`\n",
    "    :param user_id: ID de l'usuari\n",
    "    :param aisle_id: ID de la secció\n",
    "    :return: Enter amb el nombre de vegades que ha comprat\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.loc[user_id][aisle_id] #Retorna la casella ubicada per user_id i el seu aisle_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_counts = build_counts_table(df_merged)\n",
    "    count = get_count(df_counts, 14, 5)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenim moltes dades en el nostre dataset, pel que és convenient que les reduïm una mica. Per començar a treballar recomanem que reduiu el tamany a aproximadament 0.001 de l'original (`frac=0.001`). Podeu provar, més endavant, amb 0.01.\n",
    "\n",
    "A més, necessitem poder provar quan bé funciona el nostre sistema. Pel que dividirem les dades de cada usuari en 2 parts:\n",
    "\n",
    "1. **Train**: Els items que farem servir per entrenar el nostre recomanador\n",
    "2. **Test**: Dades \"ocultes\" que ens serviran per provar quant bé funciona el sistema\n",
    "\n",
    "**Nota** Pot tardar bastant aquesta cel·la!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test(df):\n",
    "    \"\"\"\n",
    "    No modifica l'estructura del DataFrame original,\n",
    "    únicament el divideix en 2 sub-DataFrame's.\n",
    "    \n",
    "    Tots dos tenen el mateix nombre d'usuaris, però cada\n",
    "    un té un conjunt diferent de producte d'aquest\n",
    "    \n",
    "    :param df: DataFrame retornat per `build_counts_table`\n",
    "    :return: Dos DataFrames amb diferents productes\n",
    "    \"\"\"\n",
    "    split = lambda i: (\n",
    "        train_test_split(row[row > 0], test_size=0.3, random_state=uid)[i] \\\n",
    "        for uid, row in df.iterrows()\n",
    "    )\n",
    "    train = pd.DataFrame(split(0)).fillna(0)\n",
    "    test = pd.DataFrame(split(1)).fillna(0)\n",
    "    return train, test\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    df_counts_train, df_counts_test = split_train_test(df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 134)\n",
      "(131, 134)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    FRAC = 0.001\n",
    "    df_reduced_counts_train = df_counts_train.sample(frac=FRAC, random_state=1)\n",
    "    df_reduced_counts_test = df_counts_test.sample(frac=FRAC, random_state=1)\n",
    "    \n",
    "    print(df_reduced_counts_test.shape)\n",
    "    print(df_reduced_counts_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph ampliat\n",
    "\n",
    "Si ara construíssim un graph com el que fèiem per les webs i generessim el vector principal, obtindríem efectívament un vector amb la importància de cada persona... però, relativa a que?\n",
    "\n",
    "<img src=\"img/Matvs.png\">\n",
    "\n",
    "Per tal de solucionar aquest problema, on no sabem que és que del pagerank resultant, el que farem serà ampliar el graph, en certa forma duplicant la informació que tenim. \n",
    "\n",
    "<img src=\"img/Matext.png\">\n",
    "\n",
    "Hauràs de construir una matriu $m+n \\times n+m$, on:\n",
    "\n",
    "* Les $m$ primeres files i les $n$ últimes columnes (indexos $0,m$) sigui la matriu que has construit anteriorment **normalitzada**\n",
    "* Les últimes $n$ files i les primeres $m$ columnes (indexos $m,0$) sigui la matriu anterior però transposada i **normalitzada**\n",
    "* La resta d'entrades, 0\n",
    "\n",
    "\n",
    "**normalitzada**: Aquesta matriu $m\\times n$ ha d'estar normalitzada per columnes (les columnes han de sumar 1). Per simplificar les imatges i que siguin més entenedores, es fan servir els valors reals. Però és molt important que normalitzeu en el vostre codi!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Funcio que pasada una matriu, la normalitza \"manualment\", ja que .norm ens donava problemes.\n",
    "def normalitzar(matriu):\n",
    "    vector = np.array(matriu.sum(axis=0)).ravel()\n",
    "    vector[vector>0]=1 / vector[vector>0]\n",
    "    vector = np.diag(vector)\n",
    "    matriu = matriu.dot(vector)\n",
    "    return matriu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm \n",
    "def get_extended_graph(df_train):\n",
    "    \"\"\"\n",
    "    Calcula el graf ampliat de prodcutes i usuaris a partir de l'original\n",
    "    \n",
    "    :param df: Sub-DataFrame del retornat per `build_counts_table`, per training\n",
    "    :return: El graf ampliat, tal i com està descrit adalt, tenint en compte\n",
    "        que la suma de cada columna ha de ser 1 (normalitzar les columnes, és a dir\n",
    "        dividir cada número de la columna pel total de la suma de la mateixa columna)\n",
    "    \"\"\"  \n",
    "    m,n = df_train.shape\n",
    "    matriu_extended = np.zeros((m+n,n+m)) #Creem la nova matriu amb les dimensions adecuades\n",
    "    matriu_extended[:m,m:] = df_train.values #Posem els valors de la matriu en els indexos 0,m de columnes\n",
    "    matriu_extended[m:,:m] = df_train.values.T #Ara, transposats i en columnes m, 0\n",
    "    \n",
    "    matriu_final = normalitzar(matriu_extended) #Normalitzem\n",
    "    return matriu_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    G = get_extended_graph(df_reduced_counts_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomanació personalitzada\n",
    "\n",
    "\n",
    "Seguim tenint un altre problema, i és, estem personalitzant res? La matriu ampliada és exactament la mateixa per cada usuari, independentment del que hagi comprat, i per tant el resultat serà sempre el mateix.\n",
    "\n",
    "Suposa que volem recomanar a l'usuari 1, el que farem serà crear una altre matriu del mateix tamany que l'anterior, on tots els elements seran 0 excepte aquelles files i columnes (corresponents a la matriu ampliada anterior) dels items que ha comprat l'usuari.\n",
    "\n",
    "<img src=\"img/Matper.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalment, la matriu sobre la qual farem el càlcul de pagerank serà la matriu ampliada perturbada per aquesta nova matriu.\n",
    "\n",
    "Anomena $G$ a la original i $E$ a aquesta que acabes de fer, i $\\bar{E}$ és $E$ normalitzada per columnes, la matriu final $G_m$ serà:\n",
    "\n",
    "$$G_m = (1-m)G + m\\bar{E}$$\n",
    "\n",
    "Que ja us hauria de sonar! Ho hem fet abans amb pagerank. Fixeu-vos que per cada usuari la matriu $G_m$ serà diferent, doncs tot i que $G$ no canvia, sí que ho fa $E$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def personalize(G, df_train, user, m=0.15):\n",
    "    \"\"\"\n",
    "    Personalitza el graf ampliat per a un usuari donat.\n",
    "    \n",
    "    La matriu E, un cop construida i abans de fer-la servir per personalitzar G,\n",
    "    s'ha de normalitzar per columnes.\n",
    "    \n",
    "    :param G: El graf ampliat\n",
    "    :param df: Sub-DataFrame del retornat per `build_counts_table`, per training\n",
    "    :param user: ID d'usuari\n",
    "    :param m: Valor de perturbació, tal i com està descrit adalt\n",
    "    :return: Matriu ampliada personalitzada\n",
    "    \"\"\"\n",
    "    \n",
    "    indexs = df_train.loc[user].loc[df_train.loc[user] != 0].index #Agafem els items comprats per l'user\n",
    "    e = np.zeros_like(G) #Creem E\n",
    "    e[df_train.shape[0]+indexs,:] = 1 #Posem un 1 en aquets indexs\n",
    "    e[:,df_train.shape[0]+indexs] = 1\n",
    "    E = normalitzar(e) #Normalitzem\n",
    "    #I apliquem la formula\n",
    "    return (1-m)*G+m*E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    Gm = personalize(G, df_reduced_counts_train, 93427)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalment, ara que ja tenim $G_m$, podem executar pagerank i obtenir el vector principal. Com pots observar a la última imatge, aquest vector tindrà $m+n$ elements, els primers $m$ corresponents als usuaris i els següents $n$ als items.\n",
    "\n",
    "Com que volem similituds entre usuaris, ens quedarem solament amb la primera part, fins a $m$. A més, el propi usuari a qui hem personalitzat la matriu no l'hem de tenir en compte, així que cal posar-l'ho a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sims_vect(Gm, df_train, user):\n",
    "    \"\"\"\n",
    "    Calcula el vector de similituds per a un usuari donat, és a dir\n",
    "    executa el metòde de la potència sobre el graf ampliat personalitzat\n",
    "    de l'usuari, i en retorna els primers M elements del vector resultant.\n",
    "    \n",
    "    A més, posa a 0 la posició del vector corresponent a l'usuari al que\n",
    "    estem recomanant.\n",
    "    \n",
    "    :param Gm: Graf ampliat personalitzat\n",
    "    :param df: Sub-DataFrame del retornat per `build_counts_table`, per training\n",
    "    :param user: ID de l'usuari\n",
    "    :return: Vector de similituds en una array de numpy\n",
    "    \"\"\"\n",
    "    #Creem un diccionari on lliguem l'index del usuari al Dataframe \n",
    "    diccionari = dict(zip(df_train.index, range(df_train.shape[0])))\n",
    "    similitud = power_method(Gm) #Metode de la potencia per calcular la similitud\n",
    "    similitud = similitud[:df_train.shape[0]] #Volem similituds entre usuaris, aixi que ens quedem nomes fins a m\n",
    "    similitud[diccionari[user]] = 0 #No em de tenir en compte el propi usuari de qui hem personalitzat la matriu\n",
    "    \n",
    "    return similitud\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    sims = sims_vect(Gm, df_reduced_counts_train, 93427)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara aplica la formula per recomanacions colaboratives donat un usuari $u$ i item $i$\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\frac{\\sum_{p,p\\neq u} sim(u,p) \\cdot r_{p,i}}{\\sum_p sim(u,p)}$$\n",
    "\n",
    "Tingues en compte que aquesta fòrmula solament té en compte aquells usuaris que també han comprat el mateix! Si no han comprat, no s'ha de comptar en el sumatori!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(df_train, user, item, sims):\n",
    "    \"\"\"\n",
    "    Fent servir la fòrmula del filtratge colaboratiu, retorna un valor\n",
    "    per a un usuari i producte\n",
    "    \n",
    "    :param df: Sub-DataFrame del retornat per `build_counts_table`, per training\n",
    "    :parma user: ID de l'usuari\n",
    "    :param item: ID de l'item\n",
    "    :param sims: Vector de similituds per a l'usuari\n",
    "    :return: Un flotant indicant el valor computat segons la fòrmula d'adalt\n",
    "    \"\"\"\n",
    "    items = df_train.loc[:,item] > 0 #Agafem els items comprats\n",
    "    superior = sims[items].dot(df_train.loc[items,item]) #Multipliquem (part de dalt de la formula)\n",
    "    inferior = sims[items].sum() #Part inferior de la formula\n",
    "    \n",
    "    if np.allclose(inferior, 0): #Tots els valors propers a zero (Molt petits) els posem a zero millor\n",
    "        return 0\n",
    "    \n",
    "    R = superior/inferior #Dividim\n",
    "    return R\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.28874260644\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(score(df_reduced_counts_train, 93427, 98, sims))\n",
    "    print(df_reduced_counts_test.loc[93427, 98])\n",
    "    print(df_reduced_counts_train.loc[93427, 98])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara, donat un usuari, recomana-li els $k$ millors productes que podria comprar. Per fer-ho, computa l'`score` per a cada possible item que encara no hagi comprat, ordena i retorna els $k$ millors.\n",
    "\n",
    "Si $k=0$, significa retornar tots els possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend(df_train, sims, user, k, score=score):\n",
    "    \"\"\"\n",
    "    Calcula l'`score` de tots els items d'un usuari, que no hagin estat ja comprats,\n",
    "    i retorna els $k$ amb valor més alt. Si $k=0$, els retorna tots ordenats de major a menor.\n",
    "    \n",
    "    :param df: Sub-DataFrame del retornat per `build_counts_table`, per training\n",
    "    :param sims: Vector de similituds\n",
    "    :param user: ID de l'usuari\n",
    "    :param k: Número de valors a retornar, o 0 per tots\n",
    "    :param score: Funció a fer servir per calcular l'score\n",
    "    :return: Llista amb els $k$ (o tots si $k=0$) items més alts. Cada element d'aquest\n",
    "        vector serà una tupla (valor, aisle_id)\n",
    "    \"\"\"\n",
    "    #Aqui hem de trobar els items amb valor mes alt, els que recomanarem. Per fer-ho, fem:\n",
    "    #Trobem els items no comprats per l'usuari (agafem els seus indexs)\n",
    "    #Per cada un d'ells, els hi calculem la seva score.\n",
    "    #Fiquem a una llista parelles (puntuacio, index del item) per cada item no comprat\n",
    "    #Ordenem aquesta llista segons la puntuacio, de petit a gran. La girem, perque volem els items amb major puntuacio\n",
    "    #Ara em de retornar k items amb major puntuacio, aixi que anem afegint a una llista final cada parella (puntuacio,item)\n",
    "    \n",
    "    llista = [] \n",
    "    noComprats = df_train.loc[user].loc[df_train.loc[user] == 0].index\n",
    "    for i in noComprats:\n",
    "        puntuacio = score(df_train, user, i, sims)\n",
    "        llista.append((puntuacio,i))\n",
    "    llista.sort(key=lambda x: x[0]) #Ordenar per puntuacio\n",
    "    llista = llista[::-1] #La girem (de gran a petit)\n",
    "    \n",
    "    llistaFinal = []\n",
    "    if k != 0:\n",
    "        for i in range(k):\n",
    "            llistaFinal.append(llista[i])\n",
    "        return llistaFinal\n",
    "    else:\n",
    "        return llista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.5184711477284623, 38), (2.4068929092679969, 24), (2.1742148610083825, 123), (2.0, 46), (2.0, 22)]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(recommend(df_reduced_counts_train, sims, 93427, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultats\n",
    "\n",
    "* No hem pogut comprovar els resultats amb molta gent, només amb un altre grup.\n",
    "* No coincideixen amb els del professor, pero si que amb aquest altre grup hem tingut pràcticament els mateixos resultats.\n",
    "* De fet, tenim els mateixos productes, pero amb una puntuacio que varia en varis decimals.\n",
    "* En conseqüència, les funcions Evaluant donen valors molt diferents si comparem amb els resultats del professor i els mateixos comparant amb aquests altre grup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluant\n",
    "\n",
    "Per saber si em fet un bon recomanador, hem d'avaluar si està funcionant correctament. Ho farem predint la puntuació de tots els items de test per un usuari, i comparant amb els valors reals.\n",
    "\n",
    "Les funcions ja estan fetes, simplement podeu executar per veure que us surt un nombre raonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(df_train, df_test, sims, user, score=score):\n",
    "    real = df_test.loc[user]\n",
    "    pred_list = recommend(df_train, sims, user, 0, score=score)\n",
    "    pred = pd.Series({y: x for x, y in pred_list})\n",
    "    \n",
    "    real = real[real > 0]\n",
    "    pred = pred.loc[real.index]\n",
    "    \n",
    "    return np.sum(np.power(real - pred, 2))\n",
    "        \n",
    "\n",
    "def mean_eval(df_train, df_test, users, score=score):\n",
    "    G = get_extended_graph(df_train)\n",
    "    return np.mean([\n",
    "        evaluate(\n",
    "            df_train, \n",
    "            df_test, \n",
    "            sims_vect(personalize(G, df_train, uid), df_train, uid), \n",
    "            uid,\n",
    "            score=score\n",
    "        ) \\\n",
    "        for uid in users if df_train.loc[uid].sum() > 0\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3152423283428418\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(evaluate(df_reduced_counts_train, df_reduced_counts_test, sims, 93427))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.36954050085\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    users = df_reduced_counts_test.sample(n=10).index\n",
    "    print(mean_eval(df_reduced_counts_train, df_reduced_counts_test, users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propostes de millora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Millorar la recomanació colaborativa\n",
    "\n",
    "La fòrmula que fem servir per calcular l'`score`, basada en la recomanació colaborativa, és força inexacta, doncs no té en compte el *bias* introduit per la mitja del comprador.\n",
    "\n",
    "Per exemple, jo potser tinc família numerosa i compro sempre 5 del mateix producte com a mínim, mentre que algú que visqui sol únicament en compraria 1 unitat.\n",
    "\n",
    "Podem eliminar aquest bias fent:\n",
    "\n",
    "$$\\hat{r}_{u,i} = \\frac{\\sum_{v,v\\neq u} sim(u,v) \\cdot (r_{v,i} - \\mu_v)}{\\sum_{v,v\\neq u} sim(u,v)} + \\mu_u$$\n",
    "\n",
    "És a dir, a cada producte d'altres persones li restem la mitja d'aquella persona ($\\mu_v$) i al final reintroduïm la mitja de l'usuari a qui estem recomanant ($\\mu_u$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_mean(df_train, user, item, sims):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(score_mean(df_reduced_counts_train, 93427, 98, sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    mean_eval(df_reduced_counts_train, df_reduced_counts_test, users, score=score_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Recalcular les mitges cada cop és molt lent, probablement voldràs tenir-les precalculades (amb una variable global o semblant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utilitzar més dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una simple inspecció de la taula de comptes, ens mostrarà que un gran percentatge està buida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    total = np.prod(df_counts.shape)\n",
    "    zero = (df_counts == 0).sum().sum()\n",
    "    nonzero = total - zero\n",
    "\n",
    "    print('Are 0: {:2.3g}%'.format(zero / total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per tant, podríem pensar que enlloc de guardar absolutament tot, solament necessitem saber les posicions on no hi ha 0's i el seu valor. Això és precisament el que fan les estructures de la llibreria\n",
    "\n",
    "```python\n",
    "import scipy.sparse as sparse\n",
    "```\n",
    "\n",
    "Tot el contingut de la llibreria `sparse` són presentacions no denses de matrius, únicament guarden els elements que són diferents de 0.\n",
    "\n",
    "Es proposa que canvieu les funcions `get_extended_matrix` i `personalize` per tal de que facin servir `sparse.lil_matrix` enlloc de `np.array`, i que augmenteu `FRAC` a `1.0` (totes les dades)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: No es tracta d'un procés trivial, treballar amb matrius sparse té cert misteri. \n",
    "\n",
    "**1.** No feu servir mai funcions de numpy sobre una matriu sparse, per exemple, supossa que `mat` és una `sparse.lil_matrix` i `dia` una matriu diagonal també `sparse.lil_matrix`:\n",
    "\n",
    "```python\n",
    "res = np.dot(mat, dia)\n",
    "```\n",
    "\n",
    "Farà el producte matricial, però la matriu resultant `res` no serà sparse sinó densa. Feu servir sempre la versió \"metòdica\" de les funcions:\n",
    "\n",
    "```python\n",
    "res = mat.dot(dia)\n",
    "```\n",
    "\n",
    "I ara, `res` és sparse, tal i com s'espera.\n",
    "\n",
    "------------------\n",
    "\n",
    "**2.** Si vols agafar una columna sencera i convertir-la a un vector dens, tal i com faria numpy, no és suficient fent:\n",
    "\n",
    "```python\n",
    "col = mat[:,0]\n",
    "```\n",
    "\n",
    "Doncs el resultat, no és un vector de $n$ elements, sinó una matriu $n,1$. Podríem pensar que aplanar el vector resultaria:\n",
    "\n",
    "```python\n",
    "col = mat[:,0].flatten() # O, equivalentment, mat[:,0].ravel()\n",
    "``` \n",
    "\n",
    "Però tampoc funcionarà. Cal convertir explícitament a array de numpy abans:\n",
    "\n",
    "```python\n",
    "col = np.array(mat[:,0]).ravel() # o flatten()\n",
    "```\n",
    "\n",
    "I, ara sí, tenim un vector de $n$ elements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
